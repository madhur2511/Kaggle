{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Understand the problem. \n",
    "   We'll look at each variable and do a philosophical analysis about their meaning and importance for this problem.\n",
    "2. Univariable study. \n",
    "   We'll just focus on the dependent variable ('SalePrice') and try to know a little bit more about it.\n",
    "3. Multivariate study. \n",
    "   We'll try to understand how the dependent variable and independent variables relate.\n",
    "4. Basic cleaning. \n",
    "   We'll clean the dataset and handle the missing data, outliers and categorical variables.\n",
    "5. Test assumptions. \n",
    "   We'll check if our data meets the assumptions required by most multivariate techniques.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "from sklearn import linear_model\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    return pd.read_csv(file_path, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def univariate_analysis(df):\n",
    "    \"\"\"Univariate Analysis of target variable\"\"\"\n",
    "    \n",
    "    print df['SalePrice'].describe()\n",
    "    sns.distplot(df['SalePrice'])\n",
    "\n",
    "    # Positive skewed\n",
    "    print df['SalePrice'].skew()\n",
    "\n",
    "    # Positive kurtosis; more prone to outliers -> \"light-tailed\"\n",
    "    print df['SalePrice'].kurt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multivariate_analysis(df):\n",
    "    \"\"\"Multivariate Analysis\"\"\"\n",
    "    # Correlation matrix\n",
    "    corrmat = df.corr()\n",
    "    f, ax = plt.subplots(figsize=(12, 9))\n",
    "    sns.heatmap(corrmat, vmax=.8, square=True)\n",
    "    plt.show()\n",
    "\n",
    "    # SalePrice correlation matrix (zoomed)\n",
    "    k = 10 #number of variables for heatmap\n",
    "    cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
    "    cm = np.corrcoef(df[cols].values.T)\n",
    "    sns.set(font_scale=1.25)\n",
    "    hm = sns.heatmap(\n",
    "        cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, \n",
    "        yticklabels=cols.values, xticklabels=cols.values\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    # 'OverallQual', 'GrLivArea' and 'TotalBsmtSF' are strongly correlated with 'SalePrice'\n",
    "    # 'GarageCars' and 'GarageArea' are also some of the most strongly correlated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def missing_data(df):\n",
    "    \"\"\"Missing data\"\"\"\n",
    "    # In this dataset, we dont really have any missing data, we conside NA as a separate category\n",
    "    perc_missing_values = train_X.isnull().sum() / train_X.shape[0]\n",
    "    perc_missing_values = perc_missing_values.sort_values(ascending=False)\n",
    "\n",
    "    # PoolQC, MiscFeature, Alley, Fence seem important variable and we wont remove them, \n",
    "    # instead, we shall convert them into boolean variables and use them in our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_massaging(df):\n",
    "    \n",
    "    # remove and replace some columns and values\n",
    "    df['LotFrontage'] = df['LotFrontage'].replace('NA', 0).astype('int64')\n",
    "    df['MasVnrArea'] = df['MasVnrArea'].replace('NA', 0).astype('int64')\n",
    "    df['TotalBsmtSF'] = df['TotalBsmtSF'].replace('NA', 0).astype('int64')\n",
    "    df['BsmtUnfSF'] = df['BsmtUnfSF'].replace('NA', 0).astype('int64')\n",
    "    df['GarageCars'] = df['GarageCars'].replace('NA', 0).astype('int64')\n",
    "    df['BsmtFullBath'] = df['BsmtFullBath'].replace('NA', 0).astype('int64')\n",
    "    df['BsmtHalfBath'] = df['BsmtHalfBath'].replace('NA', 0).astype('int64')\n",
    "\n",
    "    df = df.drop('GarageYrBlt', 1)\n",
    "    df = df.drop('GarageArea', 1)\n",
    "    df = df.drop('BsmtFinSF1', 1)\n",
    "    df = df.drop('BsmtFinSF2', 1)\n",
    "    # 1stFlrSF + 2ndFlrSF ~ GrLivArea\n",
    "    df = df.drop('GrLivArea', 1)\n",
    "    df = df.drop('Id', 1)\n",
    "\n",
    "    # separate out numeric, categorical and ordinal data-frames\n",
    "    numeric_df = df.select_dtypes(include=['int64'])\n",
    "    categorical_df = df.select_dtypes(include=['object'])\n",
    "\n",
    "    ordinal_columns = [\n",
    "        'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', \n",
    "        'BsmtFinType1', 'BsmtFinType2', 'HeatingQC', 'CentralAir', 'KitchenQual',\n",
    "        'FireplaceQu', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive',\n",
    "        'PoolQC', 'Fence'\n",
    "    ]\n",
    "    ordinal_df = pd.DataFrame(categorical_df[ordinal_columns])\n",
    "\n",
    "    non_ordinal_columns = list(set(categorical_df.columns) - set(ordinal_columns))\n",
    "    non_ordinal_df = pd.DataFrame(categorical_df[non_ordinal_columns])\n",
    "    \n",
    "    \n",
    "    # Replace ordinal categorical variables with numerical values\n",
    "    replace_rules = {\n",
    "        'ExterQual':    {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\":0},\n",
    "        'ExterCond':    {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1},\n",
    "        'BsmtQual':     {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "        'BsmtCond':     {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "        'BsmtExposure': {\"Gd\": 4, \"Av\": 3, \"Mn\": 2, \"No\": 1, \"NA\": 0},\n",
    "        'BsmtFinType1': {\"GLQ\": 6, \"ALQ\": 5, \"BLQ\": 4, \"Rec\": 3, \"LwQ\": 2, \"Unf\": 1, \"NA\": 0},\n",
    "        'BsmtFinType2': {\"GLQ\": 6, \"ALQ\": 5, \"BLQ\": 4, \"Rec\": 3, \"LwQ\": 2, \"Unf\": 1, \"NA\": 0},\n",
    "        'HeatingQC':    {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1},\n",
    "        'CentralAir':   {\"Y\": 1, \"N\": 0},\n",
    "        'KitchenQual':  {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "        'FireplaceQu':  {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "        'GarageFinish': {\"Fin\": 3, \"RFn\": 2, \"Unf\": 1, \"NA\": 0},\n",
    "        'GarageQual':   {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "        'GarageCond':   {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"NA\": 0},\n",
    "        'PavedDrive':   {\"Y\": 2, \"P\": 1, \"N\": 0},\n",
    "        'PoolQC':       {\"Ex\": 4, \"Gd\": 3, \"TA\": 2, \"Fa\": 1, \"NA\": 0},\n",
    "        'Fence':        {\"GdPrv\": 4, \"MnPrv\": 3, \"GdWo\": 2, \"MnWw\": 1, \"NA\": 0},\n",
    "    }\n",
    "    ordinal_df.replace(replace_rules, inplace=True)\n",
    "    \n",
    "    # generate dummy variables for  non-ordinal categorical variables - ONE HOT ENCODING\n",
    "    dummy_non_ordinal_df = pd.get_dummies(non_ordinal_df)\n",
    "    \n",
    "    # numerical values\n",
    "    numeric_df = numeric_df\n",
    "    \n",
    "    # merge the dataframes\n",
    "    refined_df = pd.concat([ordinal_df, dummy_non_ordinal_df, numeric_df], axis=1)\n",
    "\n",
    "    assert df.shape[0] == refined_df.shape[0]\n",
    "    return refined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_columns(df):\n",
    "    columns = sorted(df.columns)\n",
    "    return df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensure_columns_are_same(train_X, test_X):\n",
    "    incorrect_train_columns, incorrect_test_columns = set(), set()\n",
    "    incorrect_train_columns |= (set(train_X.columns) - set(test_X.columns))\n",
    "    incorrect_test_columns |= (set(test_X.columns) - set(train_X.columns))\n",
    "    \n",
    "    train_X = train_X.drop(list(incorrect_train_columns), axis=1)\n",
    "    test_X = test_X.drop(list(incorrect_test_columns), axis=1)\n",
    "    \n",
    "    assert train_X.shape[1] == test_X.shape[1]\n",
    "    return sort_columns(train_X), sort_columns(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_regression(train_X, train_y, test_X):\n",
    "    train_X, test_X = ensure_columns_are_same(train_X, test_X)\n",
    "    lm = linear_model.LinearRegression()\n",
    "    lm.fit(train_X, np.log(train_y))\n",
    "    predicted_test_y = lm.predict(test_X)\n",
    "    return lm, np.exp(predicted_test_y), train_X, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def elasticnet_regression(alpha, l1_ratio, train_X, train_y, test_X):\n",
    "    train_X, test_X = ensure_columns_are_same(train_X, test_X)\n",
    "    lm = linear_model.ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "    lm.fit(train_X, np.log(train_y))\n",
    "    predicted_test_y = lm.predict(test_X)\n",
    "    return lm, np.exp(predicted_test_y), train_X, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_regression(alpha, train_X, train_y, test_X):\n",
    "    train_X, test_X = ensure_columns_are_same(train_X, test_X)\n",
    "    lm = linear_model.Ridge(alpha=alpha)\n",
    "    lm.fit(train_X, np.log(train_y))\n",
    "    predicted_test_y = lm.predict(test_X)\n",
    "    return lm, np.exp(predicted_test_y), train_X, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lasso(alpha, train_X, train_y, test_X):\n",
    "    train_X, test_X = ensure_columns_are_same(train_X, test_X)\n",
    "    lm = linear_model.Lasso(alpha=alpha)\n",
    "    lm.fit(train_X, np.log(train_y))\n",
    "    predicted_test_y = lm.predict(test_X)\n",
    "    return lm, np.exp(predicted_test_y), train_X, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_forest_regressor(train_X, train_y, test_X, **kwargs):\n",
    "    train_X, test_X = ensure_columns_are_same(train_X, test_X)\n",
    "    lm = RandomForestRegressor(\n",
    "        max_depth=kwargs['max_depth'],\n",
    "        max_features=kwargs['max_features'],\n",
    "        min_samples_split=kwargs['min_samples_split'],\n",
    "        n_estimators=kwargs['n_estimators'],\n",
    "        min_samples_leaf=kwargs['min_samples_leaf'],\n",
    "    )\n",
    "    lm.fit(train_X, np.log(train_y))\n",
    "    predicted_test_y = lm.predict(test_X)\n",
    "    return lm, np.exp(predicted_test_y), train_X, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_regressor(train_X, train_y, test_X, **kwargs):\n",
    "    train_X, test_X = ensure_columns_are_same(train_X, test_X)\n",
    "    lm = XGBRegressor(\n",
    "        \n",
    "    )\n",
    "    lm.fit(train_X, np.log(train_y))\n",
    "    predicted_test_y = lm.predict(test_X)\n",
    "    return lm, np.exp(predicted_test_y), train_X, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RMSE(target, prediction):\n",
    "    return np.sqrt(((prediction - target) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search_report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_for_upload(predicted_test_y):\n",
    "    n = len(predicted_test_y)\n",
    "    predictions = pd.DataFrame()\n",
    "    predictions['Id'] = np.array([n + i + 1 for i in range(1, n + 1)])\n",
    "    predictions['SalePrice'] = predicted_test_y\n",
    "    predictions.to_csv('HousePrice_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_file = 'train.csv'\n",
    "test_data_file = 'test.csv'\n",
    "\n",
    "train_X = read_data(training_data_file)\n",
    "test_X = read_data(test_data_file)\n",
    "\n",
    "refined_train_X = data_massaging(train_X)\n",
    "refined_test_X = data_massaging(test_X)\n",
    "\n",
    "refined_train_y = pd.DataFrame(refined_train_X['SalePrice'])\n",
    "refined_train_X = refined_train_X.drop('SalePrice', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split the training data into train and validation sets into 2/3 and 1/3\n",
    "ref_train_X, ref_val_X, ref_train_y, ref_val_y = train_test_split(\n",
    "    refined_train_X,\n",
    "    refined_train_y,\n",
    "    test_size=0.33,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 30928.76\n",
      "Variance score: 0.87\n"
     ]
    }
   ],
   "source": [
    "model, predicted_val_y, _, _ = linear_regression(\n",
    "    ref_train_X,\n",
    "    ref_train_y,\n",
    "    ref_val_X,\n",
    ")\n",
    "print \"Mean squared error: %.2f\" % RMSE(ref_val_y, predicted_val_y)\n",
    "print \"Variance score: %.2f\" % r2_score(ref_val_y, predicted_val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 0.25\n",
      "Mean squared error: 23899.65\n",
      "Variance score: 0.92\n",
      "0.0001 0.5\n",
      "Mean squared error: 23162.83\n",
      "Variance score: 0.93\n",
      "0.0005 0.25\n",
      "Mean squared error: 26376.66\n",
      "Variance score: 0.91\n",
      "0.0005 0.5\n",
      "Mean squared error: 25918.09\n",
      "Variance score: 0.91\n",
      "0.001 0.25\n",
      "Mean squared error: 28097.25\n",
      "Variance score: 0.89\n",
      "0.001 0.5\n",
      "Mean squared error: 27723.87\n",
      "Variance score: 0.90\n",
      "0.005 0.25\n",
      "Mean squared error: 30288.42\n",
      "Variance score: 0.88\n",
      "0.005 0.5\n",
      "Mean squared error: 30953.12\n",
      "Variance score: 0.87\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.0001, 0.0005, 0.001, 0.005]:\n",
    "    for l1_ratio in [0.25, 0.5]:\n",
    "        model, predicted_val_y, _, _ = elasticnet_regression(\n",
    "            alpha,\n",
    "            l1_ratio,\n",
    "            ref_train_X,\n",
    "            ref_train_y,\n",
    "            ref_val_X,\n",
    "        )\n",
    "        print alpha, l1_ratio\n",
    "        print \"Mean squared error: %.2f\" % np.sqrt(mean_squared_error(ref_val_y, predicted_val_y))\n",
    "        print \"Variance score: %.2f\" % r2_score(ref_val_y, predicted_val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "Mean squared error: 30914.86\n",
      "Variance score: 0.87\n",
      "0.005\n",
      "Mean squared error: 30866.69\n",
      "Variance score: 0.87\n",
      "0.01\n",
      "Mean squared error: 30819.68\n",
      "Variance score: 0.87\n",
      "0.05\n",
      "Mean squared error: 30675.53\n",
      "Variance score: 0.87\n",
      "0.1\n",
      "Mean squared error: 30668.19\n",
      "Variance score: 0.87\n",
      "0.5\n",
      "Mean squared error: 30870.74\n",
      "Variance score: 0.87\n",
      "1\n",
      "Mean squared error: 30878.04\n",
      "Variance score: 0.87\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1]:\n",
    "    model, predicted_val_y, _, _ = ridge_regression(\n",
    "        alpha,\n",
    "        ref_train_X,\n",
    "        ref_train_y,\n",
    "        ref_val_X,\n",
    "    )\n",
    "    print alpha\n",
    "    print \"Mean squared error: %.2f\" % RMSE(ref_val_y, predicted_val_y)\n",
    "    print \"Variance score: %.2f\" % r2_score(ref_val_y, predicted_val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n",
      "Mean squared error: 21926.57\n",
      "Variance score: 0.93\n",
      "0.0005\n",
      "Mean squared error: 24234.87\n",
      "Variance score: 0.92\n",
      "0.001\n",
      "Mean squared error: 28521.30\n",
      "Variance score: 0.89\n",
      "0.005\n",
      "Mean squared error: 31338.23\n",
      "Variance score: 0.87\n",
      "0.01\n",
      "Mean squared error: 31709.70\n",
      "Variance score: 0.86\n",
      "0.05\n",
      "Mean squared error: 34519.78\n",
      "Variance score: 0.84\n",
      "0.1\n",
      "Mean squared error: 37284.36\n",
      "Variance score: 0.81\n",
      "0.5\n",
      "Mean squared error: 36096.95\n",
      "Variance score: 0.82\n",
      "1\n",
      "Mean squared error: 36333.84\n",
      "Variance score: 0.82\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1]:\n",
    "    model, predicted_val_y, _, _ = lasso(\n",
    "        alpha,\n",
    "        ref_train_X,\n",
    "        ref_train_y,\n",
    "        ref_val_X,\n",
    "    )\n",
    "    print alpha\n",
    "    print \"Mean squared error: %.2f\" % np.sqrt(mean_squared_error(ref_val_y, predicted_val_y))\n",
    "    print \"Variance score: %.2f\" % r2_score(ref_val_y, predicted_val_y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 33877.44\n",
      "Variance score: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel/__main__.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "random_forest_parameters = {\n",
    "    'max_features': 0.5,\n",
    "    'min_samples_split': 2,\n",
    "    'n_estimators': 20,\n",
    "    'max_depth': 10,\n",
    "    'min_samples_leaf': 1\n",
    "}\n",
    "model, predicted_val_y, _, _ = random_forest_regressor(\n",
    "    ref_train_X,\n",
    "    ref_train_y,\n",
    "    ref_val_X,\n",
    "    **random_forest_parameters\n",
    ")\n",
    "print \"Mean squared error: %.2f\" % np.sqrt(mean_squared_error(ref_val_y, predicted_val_y))\n",
    "print \"Variance score: %.2f\" % r2_score(ref_val_y, predicted_val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 31555.44\n",
      "Variance score: 0.86\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xgb_parameters = {\n",
    "    'reg_alpha': 85.303671348559149, 'colsample_bytree': 0.96827049615822469, 'learning_rate': 0.39286762857838908, 'min_child_weight': 14.049860937422956, 'n_estimators': 36, 'subsample': 0.99468429187049145, 'max_depth': 18, 'gamma': 3.9526951596517845}\n",
    "\n",
    "model, predicted_val_y, _, _ = xgb_regressor(\n",
    "    ref_train_X,\n",
    "    ref_train_y,\n",
    "    ref_val_X,\n",
    "    **xgb_parameters\n",
    ")\n",
    "print \"Mean squared error: %.2f\" % np.sqrt(mean_squared_error(ref_val_y, predicted_val_y))\n",
    "print \"Variance score: %.2f\" % r2_score(ref_val_y, predicted_val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_model_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-3e68b146ab7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgbreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_param_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefined_train_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefined_train_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_model_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_model_'"
     ]
    }
   ],
   "source": [
    "one_to_left = st.beta(10, 1)  \n",
    "from_zero_positive = st.expon(0, 50)\n",
    "xgb_param_grid = {\n",
    "    \"n_estimators\": st.randint(3, 40),\n",
    "    \"max_depth\": st.randint(3, 40),\n",
    "    \"learning_rate\": st.uniform(0.05, 0.4),\n",
    "    \"colsample_bytree\": one_to_left,\n",
    "    \"subsample\": one_to_left,\n",
    "    \"gamma\": st.uniform(0, 10),\n",
    "    'reg_alpha': from_zero_positive,\n",
    "    \"min_child_weight\": from_zero_positive,\n",
    "}\n",
    "\n",
    "xgbreg = XGBRegressor(nthreads=-1)\n",
    "\n",
    "gs = RandomizedSearchCV(xgbreg, xgb_param_grid, n_jobs=1)  \n",
    "gs.fit(refined_train_X, refined_train_y)  \n",
    "grid_search_report(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# random forest grid search; use a full grid over all parameters\n",
    "rf_param_grid = {\n",
    "    \"max_depth\": [3, 5, 7, 10],\n",
    "    \"max_features\": [1, 3, 10],\n",
    "    \"min_samples_split\": [2, 3, 10],\n",
    "    \"min_samples_leaf\": [1, 3, 10],\n",
    "    \"n_estimators\": [20, 50, 70,],\n",
    "}\n",
    "\n",
    "lm = RandomForestRegressor()\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(lm, param_grid=rf_param_grid)\n",
    "grid_search.fit(refined_train_X, refined_train_y)\n",
    "grid_search_report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model, predicted_test_y, refined_train_X, refined_test_X = linear_regression(\n",
    "    refined_train_X,\n",
    "    refined_train_y,\n",
    "    refined_test_X,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha = 0.005 \n",
    "l1_ratio = 0.25\n",
    "model, predicted_test_y, refined_train_X, refined_test_X = elasticnet_regression(\n",
    "    alpha,\n",
    "    l1_ratio,\n",
    "    refined_train_X,\n",
    "    refined_train_y,\n",
    "    refined_test_X,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha = 0.005\n",
    "model, predicted_test_y, refined_train_X, refined_test_X = ridge_regression(\n",
    "    alpha,\n",
    "    refined_train_X,\n",
    "    refined_train_y,\n",
    "    refined_test_X,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.0001\n",
    "model, predicted_test_y, refined_train_X, refined_test_X = lasso(\n",
    "    alpha,\n",
    "    refined_train_X,\n",
    "    refined_train_y,\n",
    "    refined_test_X,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel/__main__.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "random_forest_parameters = {\n",
    "    'max_features': 0.5,\n",
    "    'min_samples_split': 2,\n",
    "    'n_estimators': 20,\n",
    "    'max_depth': 10,\n",
    "    'min_samples_leaf': 1\n",
    "}\n",
    "model, predicted_test_y, refined_train_X, refined_test_X = random_forest_regressor(\n",
    "    refined_train_X,\n",
    "    refined_train_y,\n",
    "    refined_test_X,\n",
    "    **random_forest_parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# final model to upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prepare_for_upload(predicted_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try correlation analysis between some seemingly similar features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
