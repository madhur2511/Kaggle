{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from IPython.display import display\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the basic structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with writing the structure for the forest which is an ensemble of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TreeEnsemble():\n",
    "    def __init__(self, x, y, n_trees, sample_sz, min_leaf=5):\n",
    "        np.random.seed(42)\n",
    "        self.x,self.y,self.sample_sz,self.min_leaf = x,y,sample_sz,min_leaf\n",
    "        self.trees = [self.create_tree() for i in range(n_trees)] # creates n trees as a list\n",
    "\n",
    "    # creates a new decision tree from a sample subset of data\n",
    "    def create_tree(self):\n",
    "        idxs = np.random.permutation(len(self.y))[:self.sample_sz] \n",
    "        # get n rows of data, shuffle them and sample them \"sample_sz\" at a time. ie shuffle (1,n), then take sample_sz from that \n",
    "        # store those in idx as indexes of rows\n",
    "        return DecisionTree(self.x.iloc[idxs], self.y[idxs], # iloc = integer locations\n",
    "                    idxs=np.array(range(self.sample_sz)), min_leaf=self.min_leaf)\n",
    "        # self.x.iloc[idxs] = data in those shuffled rows\n",
    "        # self.y[idxs] =  data in those shuffled columns\n",
    "        # idxs = 0,sample_sz list\n",
    "        # min_leaf = passed by user or default 5\n",
    "          \n",
    "    def predict(self, x):\n",
    "        return np.mean([t.predict(x) for t in self.trees], axis=0) \n",
    "        # emsemble predict calls tree predict for each tree\n",
    "        # self.trees = the tree created in the __init__ function\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next write the class for a single decision tree, which makes the forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    def __init__(self, x, y, idxs, min_leaf=5):\n",
    "        # x = shuffled row of data\n",
    "        # y = shuffled row of response variable\n",
    "        # index = 0,sample_sz as a list\n",
    "        # min_leaf = passed by user or default 5\n",
    "        \n",
    "        self.x,self.y,self.idxs,self.min_leaf = x,y,idxs,min_leaf\n",
    "        self.n, self.c = len(idxs), x.shape[1]\n",
    "        # n = number of rows in the shuffled data\n",
    "        # c = number of columns in the shuffled data (without the response variable)\n",
    "        \n",
    "        self.val = np.mean(y[idxs]) \n",
    "        # every node in the tree is the avg of the values of the dependent variable in the branch of the tree\n",
    "        \n",
    "        self.score = float('inf')\n",
    "        # some initial score as infinity.\n",
    "        \n",
    "        self.find_varsplit()\n",
    "        \n",
    "    \n",
    "    def find_varsplit(self):\n",
    "        for i in range(self.c): self.find_better_split(i)\n",
    "            # send each column to the find_better_split() function, this returns the best row to split on, for that column.\n",
    "        if self.score == float('inf'): return\n",
    "        x = self.split_col\n",
    "        lhs = np.nonzero(x<=self.split)[0]\n",
    "        rhs = np.nonzero(x>self.split)[0]\n",
    "        self.lhs = DecisionTree(self.x, self.y, self.idxs[lhs])\n",
    "        self.rhs = DecisionTree(self.x, self.y, self.idxs[rhs])\n",
    "        \n",
    "            \n",
    "    \n",
    "    def find_better_split(self, var_idx): \n",
    "        # for a column, get the best row to split on.\n",
    "        # go through every row and and try to minimize the standard deviation\n",
    "\n",
    "        x,y = self.x.values[self.idxs,var_idx], self.y[self.idxs] \n",
    "        # self.x.values[self.idxs,var_idx] == take idxs rows (as idxs is an array) and the var_idx column\n",
    "\n",
    "        # goto each row of data and check for score\n",
    "        for i in range(1,self.n-1):\n",
    "            lhs = x<=x[i] # lhs - boolean array of 1 each time its x[i] >= x\n",
    "            rhs = x>x[i] # rhs - boolean array of 1 each time x > x[i] < x\n",
    "\n",
    "\n",
    "            if rhs.sum()==0: continue # if everything went to the left split, \n",
    "            lhs_std = y[lhs].std()\n",
    "            rhs_std = y[rhs].std()\n",
    "            curr_score = lhs_std*lhs.sum() + rhs_std*rhs.sum() # current_score = weigthed avg\n",
    "            if curr_score<self.score: \n",
    "                self.var_idx,self.score,self.split = var_idx,curr_score,x[i]\n",
    "                # returning variable name, score, and optimal row\n",
    "\n",
    "\n",
    "                # n^2 complexity\n",
    "\n",
    "    @property # decorator\n",
    "    def split_name(self): \n",
    "        return self.x.columns[self.var_idx]\n",
    "        # returns the column on which split has happened x.columns[var_idx]\n",
    "    \n",
    "    @property\n",
    "    def split_col(self): \n",
    "        return self.x.values[self.idxs,self.var_idx]\n",
    "        # returns a list of data value at x[idxs, var_idx]\n",
    "        # eg. df_raw.values[[1,2,3], 2] = will return 3 values of column 2 at rows 1,2 and 3\n",
    "\n",
    "    @property\n",
    "    def is_leaf(self): \n",
    "        return self.score == float('inf') \n",
    "        # everything that has a split, has a score to split on.\n",
    "        # this returns whether or not a node is a leaf, by comparing the score woth infinity.\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return np.array([self.predict_row(xi) for xi in x])\n",
    "\n",
    "    def predict_row(self, xi):\n",
    "        if self.is_leaf: return self.val\n",
    "        t = self.lhs if xi[self.var_idx]<=self.split else self.rhs\n",
    "        return t.predict_row(xi)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        # how to represent a tree object.\n",
    "        # __repr__ is  special function that gets called when you try to \"print\" a tree object.\n",
    "        \n",
    "        s = \"n: %s; val: %s\" % (self.n, self.val)\n",
    "#         s = 'n: {self.n}; val:{self.val}'\n",
    "        # n = number of rows in the shuffled data for that row, or for the matter of fact, in the tree.\n",
    "        # val = mean of the response variable value for that node.\n",
    "        \n",
    "        if not self.is_leaf:\n",
    "            # if the node is not a leaf, print these as well\n",
    "            \n",
    "            s += ';score: %s; split: %s; var: %s' % (self.score, self.split, self.split_name)\n",
    "#           s += '; score:{self.score}; split:{self.split}; var:{self.split_name}'\n",
    "            # score = score at that point. score is the weighted std_dev of the response variable values\n",
    "            # split = the row of data that gives the best split.\n",
    "            # split_name = the variable on which the node is spliting. basically the variable name for that node.\n",
    "            \n",
    "        return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "# 1. Import the dataset as a pandas dataframe.\n",
    "\n",
    "data_path = 'data/'\n",
    "train = pd.read_csv(data_path+'imports-85.data', header=None, na_values=[\"?\"]) #NA's are specified as ? here. So changing that\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 2. Prepare this dataset for running Random Forest. What are the steps you need to do?\n",
    "\n",
    "# 2a. Rename the columns to logical names. Use data description as reference.\n",
    "train.columns = ['symboling', 'normalized-losses', 'make', 'fuel-type', 'aspiration', 'num-of-doors',\n",
    "                'body-style', 'drive-wheels', 'engine-location', 'wheel-base', 'length', 'width', 'height',\n",
    "                'curb-weight', 'engine-type', 'num-of-cylinders', 'engine-size', 'fuel-system', \n",
    "                'bore', 'stroke', 'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg',\n",
    "                'highway-mpg', 'price']\n",
    "\n",
    "# 2b. Fix missing values. Here NA is represented by question marks '?'.\n",
    "# otherwise we could use the fillna function (eg. train['source_type'].fillna(train['source_type'].mode()[0],inplace=True))\n",
    "\n",
    "def fill_missing(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == object:\n",
    "            df[col].fillna('no_value', inplace=True)\n",
    "        else:\n",
    "            df[col].fillna(0, inplace=True)\n",
    "    return df\n",
    "        \n",
    "train = fill_missing(train) \n",
    "\n",
    "# 2c. Convert all \"object\" to category\n",
    "def convert_category(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == object:\n",
    "            df[col] = df[col].astype('category')\n",
    "    return df\n",
    "        \n",
    "train = convert_category(train)\n",
    "\n",
    "# 2d. Remove the response variable and store it as another list. \n",
    "# Here the response variable is price which is the last column.\n",
    "\n",
    "y = train.price\n",
    "X = train.drop('price', axis=1)\n",
    "\n",
    "# 2e. Convert category \n",
    "\n",
    "# OPTION 1: one hot encoded\n",
    "# X = pd.get_dummies(X)\n",
    "\n",
    "# OPTION 2: convert category to integer\n",
    "def convert_cat_to_int(df):\n",
    "    cat_columns = df.select_dtypes(['category']).columns\n",
    "    df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)\n",
    "    return df\n",
    "\n",
    "X = convert_cat_to_int(X)\n",
    "\n",
    "# 2f. split into train and validation set\n",
    "\n",
    "train_rows = int(X.shape[0]*0.8)\n",
    "X_train = X[:train_rows]\n",
    "y_train = y[:train_rows]\n",
    "\n",
    "X_valid = X[train_rows:X.shape[0]]\n",
    "y_valid = y[train_rows:X.shape[0]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TreeEnsemble():\n",
    "    def __init__(self, x, y, n_trees, sample_sz, min_leaf=5):\n",
    "        np.random.seed(42)\n",
    "        self.x,self.y,self.sample_sz,self.min_leaf = x,y,sample_sz,min_leaf\n",
    "        self.trees = [self.create_tree() for i in range(n_trees)]\n",
    "\n",
    "    def create_tree(self):\n",
    "        idxs = np.random.permutation(len(self.y))[:self.sample_sz]\n",
    "        return DecisionTree(self.x.iloc[idxs], self.y[idxs], \n",
    "                    idxs=np.array(range(self.sample_sz)), min_leaf=self.min_leaf)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return np.mean([t.predict(x) for t in self.trees], axis=0)\n",
    "\n",
    "def std_agg(cnt, s1, s2): return math.sqrt((s2/cnt) - (s1/cnt)**2)\n",
    "\n",
    "class DecisionTree():\n",
    "    def __init__(self, x, y, idxs, min_leaf=5):\n",
    "        self.x,self.y,self.idxs,self.min_leaf = x,y,idxs,min_leaf\n",
    "        self.n,self.c = len(idxs), x.shape[1]\n",
    "        self.val = np.mean(y[idxs])\n",
    "        self.score = float('inf')\n",
    "        self.find_varsplit()\n",
    "        \n",
    "    def find_varsplit(self):\n",
    "        for i in range(self.c): self.find_better_split(i)\n",
    "        if self.score == float('inf'): return\n",
    "        x = self.split_col\n",
    "        lhs = np.nonzero(x<=self.split)[0]\n",
    "        rhs = np.nonzero(x>self.split)[0]\n",
    "        self.lhs = DecisionTree(self.x, self.y, self.idxs[lhs])\n",
    "        self.rhs = DecisionTree(self.x, self.y, self.idxs[rhs])\n",
    "\n",
    "    def find_better_split(self, var_idx):\n",
    "        x,y = self.x.values[self.idxs,var_idx], self.y[self.idxs]\n",
    "        \n",
    "        # self.x.values[self.idxs,var_idx] == take idxs rows (as idxs is an array) and the var_idx column\n",
    "\n",
    "        # goto each row of data and check for score\n",
    "        for i in range(1,self.n-1):\n",
    "            lhs = x<=x[i] # lhs - boolean array of True each time its x[i] >= x\n",
    "            rhs = x>x[i] # rhs - boolean array of True each time x > x[i] < x\n",
    "            \n",
    "            if rhs.sum()==0: continue # if everything went to the left split, \n",
    "            lhs_std = y[lhs].std()\n",
    "            rhs_std = y[rhs].std()\n",
    "            curr_score = lhs_std*lhs.sum() + rhs_std*rhs.sum() # current_score = weigthed avg\n",
    "            if curr_score<self.score: \n",
    "                self.var_idx,self.score,self.split = var_idx,curr_score,x[i]\n",
    "\n",
    "    @property\n",
    "    def split_name(self): return self.x.columns[self.var_idx]\n",
    "    \n",
    "    @property\n",
    "    def split_col(self): return self.x.values[self.idxs,self.var_idx]\n",
    "\n",
    "    @property\n",
    "    def is_leaf(self): return self.score == float('inf')\n",
    "    \n",
    "    def __repr__(self):\n",
    "            # how to represent a tree object.\n",
    "            # __repr__ is  special function that gets called when you try to \"print\" a tree object.\n",
    "\n",
    "            s = \"n: %s; val: %s\" % (self.n, self.val)\n",
    "            # n = number of rows in the shuffled data for that row, or for the matter of fact, in the tree.\n",
    "            # val = mean of the response variable value for that node.\n",
    "\n",
    "            if not self.is_leaf:\n",
    "                # if the node is not a leaf, print these as well\n",
    "\n",
    "                s += ';score: %s; split: %s; var: %s' % (self.score, self.split, self.split_name)\n",
    "                # score = score at that point. score is the weighted std_dev of the response variable values\n",
    "                # split = the row of data that gives the best split.\n",
    "                # split_name = the variable on which the node is spliting. basically the variable name for that node.\n",
    "\n",
    "            return s\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return np.array([self.predict_row(xi) for xi in x])\n",
    "\n",
    "    def predict_row(self, xi):\n",
    "        if self.is_leaf: return self.val\n",
    "        t = self.lhs if xi[self.var_idx]<=self.split else self.rhs\n",
    "        return t.predict_row(xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ens = TreeEnsemble(X_train[cols], y_train.as_matrix(), 10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[n: 100; val: 12292.38;score: 737142.484286; split: 17; var: make,\n",
       " n: 100; val: 13093.88;score: 795701.067805; split: 10; var: make,\n",
       " n: 100; val: 12698.59;score: 766241.91781; split: 9; var: make,\n",
       " n: 100; val: 13293.96;score: 773640.942864; split: -1; var: symboling,\n",
       " n: 100; val: 13345.98;score: 825822.239329; split: 17; var: make,\n",
       " n: 100; val: 13696.18;score: 840021.517775; split: 17; var: make,\n",
       " n: 100; val: 12388.24;score: 802584.438034; split: 15; var: make,\n",
       " n: 100; val: 12898.73;score: 758475.099982; split: 17; var: make,\n",
       " n: 100; val: 13582.41;score: 841097.461453; split: 15; var: make,\n",
       " n: 100; val: 13320.07;score: 841716.280028; split: 17; var: make]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens.trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:83: DeprecationWarning: unorderable dtypes; returning scalar but in the future this will be an error\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 8195.73333333,  8195.73333333,  8195.73333333])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = ens.predict(X_valid[cols])\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building tree interpretations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from sklearn import metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_rmse(y_pred, y_true):\n",
    "    return np.sqrt(metrics.mean_squared_error(y_pred=y_pred, y_true=y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TreeConfidenceInterpreter():\n",
    "    def __init__(self, model, x, y):\n",
    "        self.model = model\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def tree_confidence(self):\n",
    "        preds = np.stack([t.predict(np.array(self.x)) for t in self.model.trees])\n",
    "        mean = np.mean(preds, axis=0)\n",
    "        std = np.std(preds, axis=0)\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        return list(zip(mean, std))\n",
    "    \n",
    "    def worst_rows(self, n):\n",
    "        # sort the standard deviations from worst to best and return the indexes of the top n standard deviations\n",
    "        worst_indexes = self.std.argsort()[::-1][:n]\n",
    "        \n",
    "        # data at these worst indexes\n",
    "        worst_rows = self.x.iloc[worst_indexes]\n",
    "        \n",
    "        return worst_rows\n",
    "    \n",
    "    def feature_importance(self, n):\n",
    "        # take one feature, shuffle it. \n",
    "        # get the rmse of the predicted value - true value\n",
    "        # highest rmse values are the most important 'n' features\n",
    "        \n",
    "        feature_imp = dict()\n",
    "        for feature in list(self.x):\n",
    "            x_tmp = self.x.copy()\n",
    "            x_tmp[feature] = np.random.permutation(x_tmp[feature])\n",
    "            \n",
    "            y_new_pred = ens.predict(x_tmp.values)\n",
    "            score = score_rmse(y_new_pred, self.y)\n",
    "            \n",
    "            feature_imp[feature] = score\n",
    "        return feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree_conf = TreeConfidenceInterpreter(ens, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(14959.9, 988.07974880573283),\n",
       " (14959.9, 988.07974880573283),\n",
       " (18204.5, 2662.7961220303741),\n",
       " (6531.75, 835.53270183358666),\n",
       " (6531.75, 835.53270183358666),\n",
       " (15534.5, 730.19586413509626),\n",
       " (6554.0, 630.2544459713605),\n",
       " (18204.5, 2662.7961220303741),\n",
       " (6554.0, 630.2544459713605),\n",
       " (11140.541666666668, 8149.0833990573237),\n",
       " (6531.75, 835.53270183358666),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (18204.5, 2662.7961220303741),\n",
       " (11140.541666666668, 8149.0833990573237),\n",
       " (11140.541666666668, 8149.0833990573237),\n",
       " (11140.541666666668, 8149.0833990573237),\n",
       " (6531.75, 835.53270183358666),\n",
       " (6554.0, 630.2544459713605),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (10492.104761904762, 7898.5801342311352),\n",
       " (8195.7333333333336, 3504.0999472047029),\n",
       " (6531.75, 835.53270183358666),\n",
       " (6531.75, 835.53270183358666),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (6554.0, 630.2544459713605),\n",
       " (11140.541666666668, 8149.0833990573237),\n",
       " (18204.5, 2662.7961220303741),\n",
       " (11140.541666666668, 8149.0833990573237),\n",
       " (15534.5, 730.19586413509626),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (11140.541666666668, 8149.0833990573237),\n",
       " (11140.541666666668, 8149.0833990573237),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (8195.7333333333336, 3504.0999472047029),\n",
       " (8195.7333333333336, 3504.0999472047029),\n",
       " (8195.7333333333336, 3504.0999472047029),\n",
       " (8195.7333333333336, 3504.0999472047029),\n",
       " (6554.0, 630.2544459713605),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (6554.0, 630.2544459713605),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (11140.541666666668, 8149.0833990573237),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (11140.541666666668, 8149.0833990573237),\n",
       " (10492.104761904762, 7898.5801342311352),\n",
       " (10492.104761904762, 7898.5801342311352),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (10492.104761904762, 7898.5801342311352),\n",
       " (12340.316666666668, 10289.189964796387),\n",
       " (8195.7333333333336, 3504.0999472047029),\n",
       " (11140.541666666668, 8149.0833990573237),\n",
       " (18204.5, 2662.7961220303741),\n",
       " (18204.5, 2662.7961220303741),\n",
       " (6531.75, 835.53270183358666),\n",
       " (6531.75, 835.53270183358666),\n",
       " (6531.75, 835.53270183358666),\n",
       " (6554.0, 630.2544459713605),\n",
       " (8195.7333333333336, 3504.0999472047029),\n",
       " (8195.7333333333336, 3504.0999472047029),\n",
       " (14959.9, 988.07974880573283),\n",
       " (14959.9, 988.07974880573283),\n",
       " (14959.9, 988.07974880573283),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (10492.104761904762, 7898.5801342311352),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6531.75, 835.53270183358666),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (8195.7333333333336, 3504.0999472047029),\n",
       " (8195.7333333333336, 3504.0999472047029),\n",
       " (6554.0, 630.2544459713605),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (11140.541666666668, 8149.0833990573237),\n",
       " (11140.541666666668, 8149.0833990573237),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (11140.541666666668, 8149.0833990573237),\n",
       " (11140.541666666668, 8149.0833990573237),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (10492.104761904762, 7898.5801342311352),\n",
       " (14959.9, 988.07974880573283),\n",
       " (8195.7333333333336, 3504.0999472047029),\n",
       " (14959.9, 988.07974880573283),\n",
       " (14959.9, 988.07974880573283),\n",
       " (14959.9, 988.07974880573283),\n",
       " (18204.5, 2662.7961220303741),\n",
       " (11140.541666666668, 8149.0833990573237),\n",
       " (15534.5, 730.19586413509626),\n",
       " (8195.7333333333336, 3504.0999472047029),\n",
       " (6531.75, 835.53270183358666),\n",
       " (8195.7333333333336, 3504.0999472047029),\n",
       " (6531.75, 835.53270183358666),\n",
       " (8195.7333333333336, 3504.0999472047029),\n",
       " (6531.75, 835.53270183358666),\n",
       " (6531.75, 835.53270183358666),\n",
       " (6531.75, 835.53270183358666),\n",
       " (6531.75, 835.53270183358666),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (6554.0, 630.2544459713605),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (7855.5047619047618, 142.83629562173189),\n",
       " (6554.0, 630.2544459713605)]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_conf.tree_confidence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symboling</th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>make</th>\n",
       "      <th>fuel-type</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>num-of-doors</th>\n",
       "      <th>body-style</th>\n",
       "      <th>drive-wheels</th>\n",
       "      <th>engine-location</th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>...</th>\n",
       "      <th>num-of-cylinders</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>fuel-system</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>115.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>234</td>\n",
       "      <td>5</td>\n",
       "      <td>3.46</td>\n",
       "      <td>3.10</td>\n",
       "      <td>8.3</td>\n",
       "      <td>155.0</td>\n",
       "      <td>4750.0</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>114.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>3.46</td>\n",
       "      <td>2.19</td>\n",
       "      <td>8.4</td>\n",
       "      <td>95.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>3</td>\n",
       "      <td>3.39</td>\n",
       "      <td>3.39</td>\n",
       "      <td>22.7</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4650.0</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>114.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>152</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.52</td>\n",
       "      <td>21.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>326</td>\n",
       "      <td>5</td>\n",
       "      <td>3.54</td>\n",
       "      <td>2.76</td>\n",
       "      <td>11.5</td>\n",
       "      <td>262.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>5</td>\n",
       "      <td>3.63</td>\n",
       "      <td>4.17</td>\n",
       "      <td>8.1</td>\n",
       "      <td>176.0</td>\n",
       "      <td>4750.0</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>94.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>3.11</td>\n",
       "      <td>9.6</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>38</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>94.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.23</td>\n",
       "      <td>8.5</td>\n",
       "      <td>78.0</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>24</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>120.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>308</td>\n",
       "      <td>5</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.35</td>\n",
       "      <td>8.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96.1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "      <td>5</td>\n",
       "      <td>3.46</td>\n",
       "      <td>3.90</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     symboling  normalized-losses  make  fuel-type  aspiration  num-of-doors  \\\n",
       "71          -1                0.0     9          1           0             0   \n",
       "113          0                0.0    13          1           0             0   \n",
       "63           0                0.0     8          0           0             1   \n",
       "114          0                0.0    13          0           1             0   \n",
       "49           0                0.0     7          1           0             2   \n",
       "48           0                0.0     7          1           0             0   \n",
       "45           0                0.0     6          1           0             0   \n",
       "43           0                0.0     6          1           0             0   \n",
       "73           0                0.0     9          1           0             0   \n",
       "130          0                0.0    16          1           0             0   \n",
       "\n",
       "     body-style  drive-wheels  engine-location  wheel-base     ...       \\\n",
       "71            3             2                0       115.6     ...        \n",
       "113           4             2                0       114.2     ...        \n",
       "63            3             1                0        98.8     ...        \n",
       "114           4             2                0       114.2     ...        \n",
       "49            3             2                0       102.0     ...        \n",
       "48            3             2                0       113.0     ...        \n",
       "45            3             1                0        94.5     ...        \n",
       "43            3             2                0        94.3     ...        \n",
       "73            3             2                0       120.9     ...        \n",
       "130           4             1                0        96.1     ...        \n",
       "\n",
       "     num-of-cylinders  engine-size  fuel-system  bore  stroke  \\\n",
       "71                  0          234            5  3.46    3.10   \n",
       "113                 2          120            5  3.46    2.19   \n",
       "63                  2          122            3  3.39    3.39   \n",
       "114                 2          152            3  3.70    3.52   \n",
       "49                  5          326            5  3.54    2.76   \n",
       "48                  3          258            5  3.63    4.17   \n",
       "45                  2           90            1  3.03    3.11   \n",
       "43                  2          111            1  3.31    3.23   \n",
       "73                  0          308            5  3.80    3.35   \n",
       "130                 2          132            5  3.46    3.90   \n",
       "\n",
       "     compression-ratio  horsepower  peak-rpm  city-mpg  highway-mpg  \n",
       "71                 8.3       155.0    4750.0        16           18  \n",
       "113                8.4        95.0    5000.0        19           24  \n",
       "63                22.7        64.0    4650.0        36           42  \n",
       "114               21.0        95.0    4150.0        25           25  \n",
       "49                11.5       262.0    5000.0        13           17  \n",
       "48                 8.1       176.0    4750.0        15           19  \n",
       "45                 9.6        70.0    5400.0        38           43  \n",
       "43                 8.5        78.0    4800.0        24           29  \n",
       "73                 8.0       184.0    4500.0        14           16  \n",
       "130                8.7         0.0       0.0        23           31  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_conf.worst_rows(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_imp = tree_conf.feature_importance(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAFMCAYAAAAgMXAJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cc8c0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "plt.bar(range(len(feat_imp)), feat_imp.values(), align='center')\n",
    "plt.xticks(range(len(feat_imp)), feat_imp.keys(), rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree Interpretor\n",
    "\n",
    "gives you prediction, bias and confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tree_interpretor(model, X_row):\n",
    "    # this is for only 1 row of data\n",
    "    \n",
    "    # return a triple of [prediction, bias and feature_contributions],  \n",
    "    # such that prediction ≈ bias + feature_contributions.\n",
    "    \n",
    "    # prediction at each level = bias + score of the feature at that level.\n",
    "    \n",
    "    biases = []\n",
    "    contributions = []\n",
    "    predictions = []\n",
    "    \n",
    "    for t in model.trees:\n",
    "\n",
    "        # bias is the mean given by the topmost split\n",
    "        _bias = t.val # value at first split\n",
    "        biases.append(_bias)\n",
    "        \n",
    "        old_node_val = _bias # to take old_node_value across the tree\n",
    "        \n",
    "        _temp_contribution = {} # dict to store score at each node\n",
    "        while not t.is_leaf:\n",
    "            \n",
    "            # for each split node in the tree, get the contribution\n",
    "            feature = t.split_name\n",
    "       \n",
    "            t = t.lhs if X_row[feature] <= t.split else t.rhs # which branch to consider next\n",
    "        \n",
    "            # new_node_val is the response at the new node of the tree\n",
    "            new_node_val = t.val\n",
    "            \n",
    "            # feature_contribution = value at this level - value at prev level\n",
    "            _temp_contribution[feature] = new_node_val - old_node_val\n",
    "            \n",
    "            # update the value for next iteration\n",
    "            old_node_val = new_node_val\n",
    "            \n",
    "        # when the loop gets over, we were just above the leaf node.\n",
    "        # t.lhs or t.rhs -> leaf node. \n",
    "        # thus new_node_value -> prediction\n",
    "        predictions.append(new_node_val) \n",
    "        \n",
    "        contributions.append(_temp_contribution)\n",
    "        \n",
    "    return [predictions, biases, contributions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction, bias, contributions = tree_interpretor(ens, ens.x.loc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'make': 6832.2391304347821, 'symboling': -2822.0},\n",
       " {'make': -4811.726190476189, 'symboling': 242.14285714285688},\n",
       " {'make': -971.25, 'symboling': -1406.25},\n",
       " {'make': 1801.25, 'symboling': 6478.2132867132877},\n",
       " {'make': -4689.1071428571413, 'symboling': -2783.75},\n",
       " {'make': 146.0, 'symboling': 5454.4971428571407},\n",
       " {'make': 7000.7658730158746, 'symboling': -1101.0},\n",
       " {'make': 1236.6666666666661, 'symboling': 6779.2521645021625},\n",
       " {'make': 5442.2916666666661, 'symboling': -331.5},\n",
       " {'make': -1658.75}]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importance = Contribution from each row of the tree interpretor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def feature_importance_tree(contributions):\n",
    "    \n",
    "    feature_importance = defaultdict(int)\n",
    "    for contribution in contributions:\n",
    "        for (k,v) in contribution.items():\n",
    "            feature_importance[k] += v\n",
    "            \n",
    "    return (feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_importance  = feature_importance_tree(contributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'make': 10328.380003450658, 'symboling': 10509.605451215448})"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aspiration': 9049.3174169083268,\n",
       " 'body-style': 9049.3174169083268,\n",
       " 'bore': 9049.3174169083268,\n",
       " 'city-mpg': 9049.3174169083268,\n",
       " 'compression-ratio': 9049.3174169083268,\n",
       " 'curb-weight': 9049.3174169083268,\n",
       " 'drive-wheels': 9049.3174169083268,\n",
       " 'engine-location': 9049.3174169083268,\n",
       " 'engine-size': 9049.3174169083268,\n",
       " 'engine-type': 9049.3174169083268,\n",
       " 'fuel-system': 9049.3174169083268,\n",
       " 'fuel-type': 9049.3174169083268,\n",
       " 'height': 9049.3174169083268,\n",
       " 'highway-mpg': 9049.3174169083268,\n",
       " 'horsepower': 9049.3174169083268,\n",
       " 'length': 9049.3174169083268,\n",
       " 'make': 9049.1082057910207,\n",
       " 'normalized-losses': 10080.135149712514,\n",
       " 'num-of-cylinders': 9049.3174169083268,\n",
       " 'num-of-doors': 9049.3174169083268,\n",
       " 'peak-rpm': 9049.3174169083268,\n",
       " 'stroke': 9049.3174169083268,\n",
       " 'symboling': 8977.2072142867546,\n",
       " 'wheel-base': 9049.3174169083268,\n",
       " 'width': 9049.3174169083268}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
